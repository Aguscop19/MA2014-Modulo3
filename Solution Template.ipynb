{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution Template\n",
    "\n",
    "Use this notebook as a guide to implement your solution. Keep in mind that some cells should remain as they are so that you code works properly, for instance, the following cell in which the required libraries are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import hamming\n",
    "# Add more libraries in case you need them in this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localization\n",
    "\n",
    "Hidden Markov Models (HMM) are used in a wide variety of applications such as speech recognition, part-of-speech tagging, machine traslation, handwriting recognition and many more. In this section we will see how HMM can be employed to infer the position of a robot in a static enviroment.\n",
    "\n",
    "Let us represent the enviroment in which the robot roams around by a grid. Each square of the grid is either free or occupied, in which case we are talking about a position that the robot can not visit. Let $X_k$ be the position of the robot at time $t_k$. Given the latter, all the possible states of $X_k$ are the free spots of the grid: $S\\{s_1,s_2,\\dots,s_n\\}$, where $n$ is the number of free squares. Speaking of \"free squares,\" suppose we do not know where the robot is, so $P(X_0)=1/n$, $\\forall s_i\\in S$. Also, let $\\text{neighnors}(s)$ be the set of empty squares adjacent to $s$ and let $N(s)$ be the size of this set. Then, the transition model of a robot that moves to any adjacent and empty square with equal probability is given by\n",
    "\n",
    "$$\n",
    "P(X_{k+1}=s_j|X_k=s_i)=T_{ij}=\n",
    "\\begin{cases}\n",
    "\\frac{1}{N(s_i)}~, & s_j\\in \\text{neighbors}(s_i)\\\\\n",
    "0, & s_j\\notin \\text{neighbors}(s_i)\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "As it was mentioned, the robot will try to know where it is located given a set of observations. In this case, the robot is equipped with four sensors that indicate if there is an obstacle or not in a particular direction. We will assume all the possible directions are North (N), East (E), West (W) and South (S). Further, there is a sensor error rate $\\epsilon$ and errors occur independently in the four sensor directions. For instance, the probability of getting all four measurements right is $(1-\\epsilon)^4$, the probability of getting them all wrong is $\\epsilon^4$. Given this, we have that there are 16 possible measurements for $E_k$ at a given time $t_k$. Also, let $d_{ik}$ be the discrepancy: the number of bits that are different from the true bits for the square $s_i$. Then, the probability that a robot in square $s_i$ would get a reading $e_k$ is equal to\n",
    "\n",
    "$$\n",
    "P(E_k=e_k|X_k=s_i)=O_{e_k,ii}=(1-\\epsilon)^{4-d_{~ik}}~\\epsilon^{~d_{~ik}}.\n",
    "$$\n",
    "\n",
    "For instance, the probability that a square with obstacles to the North and South would produce a reading (N,S,E) is equal to $(1-\\epsilon)^3~\\epsilon$.\n",
    "\n",
    "Now that we know how to define the transition and sensor models we can carry out different types of inference: we can estimate a location given a set of measurements doing filtering; we can use smoothing to infer a past location given some observations; or we can use the Viterbi algorithm and obtain the most likely path that the robot took and that produced a given set of sensor values.\n",
    "\n",
    "<img src=\"robot.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "Your mission is to carry out these three types of inference. In particular, for both filtering and smoothing, instead of using something like the figures shown above, use heatmaps in which the color changes depending on the probability of finding the robot at a certain square given a set of measurements. For the most likely path highlight the squares associated to said path. Keep in mind that you will have to simulate the random behavior of the sensors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Model\n",
    "\n",
    "Let us define some matrices. Say we have $k$ possible states: $S=\\{s_1,s_2\\dots,s_k\\}$. Then, the **transition matrix** is a $k\\times k$ matrix in which $T_{ij} = P(X_{k+1}=s_j|X_{k}=s_i)$. In this case, each state is a position that can be occupied by the robot, or in other words, a free cell. Notice that in the map there are a total of 42 free cells, which means that the system has 42 possible states. The latter implies that the transitions matrix is a $42\\times42$ matrix.\n",
    "\n",
    "Use the following cell to write a code that computes the transition matrix. You might need more than one cell to do this in an organized fashion, so feel free to add as many cells as you want.\n",
    "\n",
    "<img src=\"/workspaces/MA2014-Modulo3/robot-casillas-numeradas.png\" alt=\"Mapa Robot\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"INSERT YOUR CODE HERE\"\n",
    "#crear una matriz de ceros de 42x42\n",
    "mt = np.zeros((42,42))\n",
    "mt[0,1] = 1\n",
    "mt[1,0] = 1/2; mt[1,13] = 1/2\n",
    "mt[2,3] = 1/2; mt[2,15] = 1/2\n",
    "mt[3,2] = 1/2; mt[3,4] = 1/2\n",
    "mt[4,3] = 1/2; mt[4,16] = 1/2\n",
    "mt[5,6] = 1\n",
    "mt[6,5] = 1/3; mt[6,7] = 1/3; mt[6,17] = 1/3\n",
    "mt[7,6] = 1/3; mt[7,8] = 1/3; mt[7,18] = 1/3\n",
    "mt[8,7] = 1/2; mt[8,19] = 1/2\n",
    "mt[9,21] = 1/2; mt[7,8] = 1/2\n",
    "mt[10,9] = 1/2; mt[10,11] = 1/2\n",
    "mt[11,10] = 1/2; mt[11,12] = 1/2\n",
    "mt[12,11] = 1/2; mt[12,22] = 1/2\n",
    "mt[13,1] = 1/2; mt[13,14] = 1/2\n",
    "mt[14,13] = 1/3; mt[14,15] = 1/3; mt[14,23] = 1/3\n",
    "mt[15,2] = 1/3; mt[15,14] = 1/3; mt[15,24] = 1/3\n",
    "mt[16,4] = 1/2; mt[16,25] = 1/2\n",
    "mt[17,6] = 1/3; mt[17,18] = 1/3; mt[17,26] = 1/3\n",
    "mt[18,7] = 1/3; mt[18,17] = 1/3; mt[18,19] = 1/3\n",
    "mt[19,8] = 1/4; mt[19,18] = 1/4; mt[19,20] = 1/4; mt[19,27] = 1/4\n",
    "mt[20,19] = 1/2; mt[20,21] = 1/2\n",
    "mt[21,9] = 1/2;  mt[21,28] = 1/2\n",
    "mt[22,12] = 1\n",
    "mt[23,14] = 1/3; mt[23,24] = 1/3; mt[23,31] = 1/3\n",
    "mt[24,15] = 1/3; mt[24,23] = 1/3; mt[24,32] = 1/3\n",
    "mt[25,16] = 1/2; mt[25,33] = 1/2\n",
    "mt[26,17] = 1/2; mt[26,36] = 1/2\n",
    "mt[27,19] = 1\n",
    "mt[28,21] = 1/2; mt[28,39] = 1/2\n",
    "mt[29,30] = 1\n",
    "mt[30,29] = 1/2; mt[30,31] = 1/2\n",
    "mt[31,23] = 1/3; mt[31,30] = 1/3; mt[31,32] = 1/3\n",
    "mt[32,24] = 1/2; mt[32,31] = 1/2\n",
    "mt[33,25] = 1/2; mt[33,34] = 1/2\n",
    "mt[34,33] = 1/2; mt[34,35] = 1/2\n",
    "mt[35,34] = 1/2; mt[35,36] = 1/2\n",
    "mt[36,26] = 1/3; mt[36,35] = 1/3; mt[36,37] = 1/3\n",
    "mt[37,36] = 1\n",
    "mt[38,39] = 1\n",
    "mt[39,28] = 1/3; mt[39,38] = 1/3; mt[39,40] = 1/3\n",
    "mt[40,39] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, define a dictionary that will contain all the possible states of the system. Remember that each state is a location that can be stored as a tuple. Pick the origin as the lower left corner of the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Store the states of the system in a dictionary following this format:\n",
    "    S = {0: (0,0), 1: (1, 0), ..., 41: (15, 3)} \n",
    "\"\"\"\n",
    "\n",
    "S = {0:(0,0), 1:(1,0) , 2:(3,0), 3:(4,0), 4:(5,0), 5:(7,0), 6:(8,0), 7:(9,0), 8:(10,0), 9:(12,0), 10:(13,0), 11:(14,0), 12:(15,0),\n",
    "    13:(1,1), 14:(2,1), 15:(3,1), 16:(5,1), 17:(8,1), 18:(9,1), 19:(10,1), 20:(11,1), 21:(12,1), 22:(15,1), \n",
    "    23:(2,2), 24:(3,2), 25:(5,2), 26:(8,2), 27:(10,2), 28:(12,2),\n",
    "    29:(0,3), 30:(1,3), 31:(2,3), 32:(3,3), 33:(5,3), 34:(6,3), 35:(7,3), 36:(8,3), 37:(9,3), 38:(11,3), 39:(12,3), 40:(13,3), 41:(15,3)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor Model\n",
    "\n",
    "At this point you know that there are 16 possible measurements for $E_k$ at a given time $t_k$. For each measurement you will need to define a matrix that stores the probabilities of getting a reading $e_k$ given that the robot is at the location $s_i$:\n",
    "\n",
    "$$\n",
    "P(E_k=e_k|X_k=s_i)=O_{e_k,ii}=(1-\\epsilon)^{4-d_{~ik}}~\\epsilon^{~d_{~ik}}.\n",
    "$$\n",
    "\n",
    "In the following cell, write code for computing the matrices of the sensor model. Notice that you will have to define an error rate $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear una matriz de 42x1 para la cantidad de vecinos de cada casilla\n",
    "sn = np.zeros((42,1))\n",
    "sn[0] = 1; sn[1:5] = 2; sn[5] = 1; sn[6:8] = 3; sn[8:14] = 2; sn[14:16] = 3; sn[16] = 2; sn[17:19] = 3; sn[19] = 4\n",
    "sn[20:22] = 2; sn[22] = 1; sn[23:25] = 3; sn[25:27] = 2; sn[27] = 1; sn[28] = 2; sn[29] = 1; sn[30] = 2; sn[31] = 3; sn[32:36] = 2\n",
    "sn[36] = 3; sn[37:39] = 1; sn[39] = 3; sn[40] = 1; sn[41] = 0\n",
    "#Pensandolo mejor creo que es mejor tener la una matriz con la lectura correcta de los sensores y despues calcular distancia hamiltoniana para \n",
    "#calcular la cantidad de bits diferentes y poner la probabilidad de cada lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear matriz con la lectura correcta de los sensores, hacer esto con alguien mas aka Jesus para que a escribirlo\n",
    "sr = np.zeros((42,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "#Crear una funcion para calcular la distancia hamiltoniana, se uso la libreria scipy \n",
    "def distanciaHamiltoniana(a,b):\n",
    "    x = hamming(a,b)*len(a)\n",
    "    return x\n",
    "\n",
    "print(distanciaHamiltoniana([1,1,1,1],[0,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"INSERT YOUR CODE HERE\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the readings can be understood as binary numbers of four digits: `0000`, `0001`,..., `1111`. Regarding the order of the binary measurements, use this convention: `ESWN`; that is, if the robot has obstacles in both the North and East directions, then an error-free measurement should be the binary number `1001`. For convenience, store the \"observation matrices\" in a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Store the states of the system in a dictionary following this format:\n",
    "    O = {0000: Matrix of measurement 0000, ..., 1111: Matrix of measurement 1111}\n",
    "\"\"\"\n",
    "\n",
    "O ={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "In this context, **filtering** can be used to get an idea of the robot's location given a set of measurements. As it was mentioned in class, this type of inference is the act of, given some evidence up to a time $t_k$, we want to infer what is the probability distribution of the state $X_k$: $P(X_k|E_{1:k}=e_{1:k})$. Provide the `filtering` function with some evidence, which is going to be a sequence of bynary numbers of four digits, and compute the probability distribution of the state of the system at time $t_k$. Notice that said distribution should be a vector of 42 components. Do not forget to take into account the stochastic nature of the measurement process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(E, O, T, X0):\n",
    "    \n",
    "    forward = X0\n",
    "    \n",
    "    for evidence in E:\n",
    "        forward = O[evidence] @ T.T @ forward\n",
    "        forward = forward / forward.sum()\n",
    "        \n",
    "    return forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "E = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize\n",
    "\n",
    "Visualize your results using a heatmap. The `seaborn` library might be very useful for this purpose. In order to do this, write a function that receives the vector $X_k$ and returns a heatmap of a $4\\times16$ matrix in which each entry is the probability that the robot is occupying the location associated to said entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_heatmap(state):\n",
    "    \n",
    "    \"\"\"\n",
    "    The purpose of this function is to create a heatmap based on the state of the system at a given time. \n",
    "    The variable state is a vector of 42 components where each entry is the probability of finding the robot \n",
    "    at a certain location. The function does not have to return anything, it should just show the heatmap.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_heatmap(filtering(E, O, T, X0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing\n",
    "\n",
    "As for **smoothing**, we can use it to infer a past state given a set of measurements: that is, we wish to obtain $P(X_j|E_{1:k}=e_{1:k})$, $1\\leq j<k$. Supply some evidence and run the `smoothing` function. Check that what the functions returns makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(E, O, T, X0, k):\n",
    "    \n",
    "    forward = filtering(E[:k], O, T, X0)\n",
    "    \n",
    "    backward = np.ones((T.shape[0],1))\n",
    "    \n",
    "    for evidence in E[-1:k-1:-1]:\n",
    "        backward = T @ O[evidence] @ backward\n",
    "    \n",
    "    smooth = forward * backward\n",
    "    smooth = smooth / smooth.sum()\n",
    "    \n",
    "    return smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = []\n",
    "\n",
    "view_heatmap(smoothing(E, O, T, X0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Likely Sequence of States\n",
    "\n",
    "Finally, for obtaining the most likely sequence that produced the given evidence, we need to compute\n",
    "\n",
    "$$\n",
    "\\max_{x_{1:k}}P(x_{1:k}|E_{1:k}=e_{1:k}).\n",
    "$$\n",
    "\n",
    "As it was mentioned in class, the most likely sequence is the one that has the highest probability, which is obtained by the **Viterbi algorithm**. \n",
    "\n",
    "For this part of the assignment, pick a path in advance and record the set of measurements the robot would take along the road. Do not forget to include the possibility of getting some incorrect measurements in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_likely_sequence(E, O, S, T, X0):\n",
    "    \n",
    "    sequences = np.zeros((T.shape[0], len(E)))\n",
    "    states = np.zeros((T.shape[0], len(E)))\n",
    "    ones = np.ones((T.shape[0], T.shape[0]))\n",
    "    sequences[:, 0] = (O[E[0]] @ X0).reshape((T.shape[0],))\n",
    "    message = sequences[:, 0].reshape((T.shape[0], 1))\n",
    "    \n",
    "    for i, evidence in enumerate(E[1:]):\n",
    "        message = (T @ O[evidence]) * (message * ones)\n",
    "        states[:, i+1] = np.argmax(message, axis=0).reshape((T.shape[0],))\n",
    "        message = np.max(message, axis=0).reshape((T.shape[0], 1))\n",
    "        sequences[:, i+1] = message.reshape((T.shape[0],))\n",
    "        \n",
    "    states = states.astype('int32')\n",
    "    s = np.argmax(sequences[:, -1], axis=0)\n",
    "    best_sequence = [S[s]]\n",
    "    \n",
    "    for i in range(len(E)-1, 0, -1):\n",
    "        s = states[s, i]\n",
    "        best_sequence.append(S[s])\n",
    "        \n",
    "    best_sequence = best_sequence[::-1] \n",
    "    \n",
    "    return best_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = []\n",
    "\n",
    "most_likely_sequence(E, O, S, T, X0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization purposes, define a vector of 42 components in which the entry associated to a state that belongs to the most likely sequence is set to one, otherwise, set the entry to zero. Call the `view_heatmap` function, which should receive the vector that you just defined as an input, and obtain the corresponding heatmap. The shown path should be the sequence of locations that the robot occupied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You will have to write some code here for computing your vector of zeros and ones. Store this information\n",
    "as \"vector\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_heatmap(vector)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
